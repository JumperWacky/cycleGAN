{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP4u5+4URtkAnOEOuLXcG2O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JumperWacky/cycleGAN/blob/main/mnist_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "a0lE0pmW1Pzy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import pandas,numpy,random\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset类，用于data预处理，data传入等\n",
        "class MnistDataset(Dataset):\n",
        "  def __init__(self, csv_file):\n",
        "    count = 0\n",
        "    with open(csv_file) as rf:\n",
        "      for line in rf:\n",
        "        count += 1\n",
        "        items = line.strip().split(',')\n",
        "        if count == 577:\n",
        "          print(line)\n",
        "          print(len(items))\n",
        "    self.data_df = pandas.read_csv(csv_file, header=None)\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.data_df)\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    # 图像label one-hot编码\n",
        "    label = self.data_df.iloc[index, 0]\n",
        "    target = torch.zeros(10)\n",
        "    target[label] = 1.0\n",
        "\n",
        "    # 图像数据\n",
        "    # iloc生成一个二维区域，values生成一个numpy.array\n",
        "    image_values = torch.FloatTensor(self.data_df.iloc[index, 1:].values) / 255.0\n",
        "\n",
        "    # 返回标签、图像数据张量及目标张量\n",
        "    return label, image_values, target\n",
        "  \n",
        "  def plot_image(self, index):\n",
        "    arr = self.data_df.iloc[index, 1:].values.reshape(28, 28)\n",
        "    plt.title(\"label = \" + str(self.data_df.iloc[index,0]))\n",
        "    plt.imshow(arr, interpolation='none', cmap='Blues')\n",
        "    pass"
      ],
      "metadata": {
        "id": "T15Cw5FI1oOz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load Data\n",
        "mnist_dataset = MnistDataset(\"/content/sample_data/mnist_train.csv\")\n",
        "mnist_dataset.plot_image([20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "k9pmFN641o7k",
        "outputId": "8eb8b828-adc6-4563-d376-893a59e57a9c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,66,189,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,226,232,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,61,245,129,0,0,0,0,0,24,27,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,21,191,254,97,0,0,0,0,0,114,213,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,72,254,254,11,0,0,0,0,34,218,243,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,72,254,254,11,0,0,0,33,162,254,243,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,72,254,254,17,18,126,152,247,254,252,254,102,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,65,239,254,254,254,254,249,194,113,189,248,47,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,33,199,213,213,193,73,0,0,232,243,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,232,243,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,232,206,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,127,254,254,255,169,146,146,146,146,146,103,17,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,253,253,253,253,253,253,253,253,253,253,253,145,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,165,248,248,248,252,251,252,253,253,253,253,221,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,81,50,68,178,253,253,253,202,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,80,241,253,253,220,77,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,97,221,245,253,252,168,34,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,38,103,177,253,253,253,253,93,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,28,92,195,240,253,253,253,253,196,79,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,100,239,253,253,253,253,253,253,95,7,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,253,253,253,253,253,253,253,253,246,137,55,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,173,253,253,253,253,253,253,253,253,253,253,134,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,28,124,124,124,41,23,124,124,179,237,253,252,76,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,46,242,253,81,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,206,253,168,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,74,11,0,0,0,0,0,7,211,253,177,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,58,199,251,72,0,0,0,0,0,88,253,253,81,0,0,0,0,0,0,0,0,0,0,0,0,0,0,95,236,253,63,0,0,0,23,104,205,239,253,253,81,0,0,0,0,0,0,0,0,0,0,0,0,0,0,220,253,253,152,141,178,249,250,253,253,253,241,106,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,222,253,253,253,253,253,253,253,253,253,207,67,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,176,253,253,253,186,145,145,145,145,90,13,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
            "\n",
            "1188\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-d4182a01dae9>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load Data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmnist_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMnistDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/sample_data/mnist_train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmnist_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-980e15c71305>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, csv_file)\u001b[0m\n\u001b[1;32m     10\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1251\u001b[0m             \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1253\u001b[0;31m                 \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1254\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 785 fields in line 577, saw 1188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_random(size=4):\n",
        "  random_data = torch.rand(size)\n",
        "  return random_data"
      ],
      "metadata": {
        "id": "4s8a9wFC7PPZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 构造鉴别器\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self) -> None:\n",
        "    super().__init__()\n",
        "\n",
        "    # 定义神经网路层\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(784, 200),\n",
        "        nn.Sigmoid(),\n",
        "        nn.Linear(200, 1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "    # 创建损失函数\n",
        "    self.loss_function = nn.MSELoss()\n",
        "\n",
        "    # 创建优化器\n",
        "    self.optimizer = torch.optim.SGD(self.parameters(), lr=0.01)\n",
        "\n",
        "    # 计数器和进程记录\n",
        "    self.counter = 0\n",
        "    self.progress = []\n",
        "\n",
        "    pass\n",
        "  \n",
        "  def forward(self, inputs):\n",
        "    return self.model(inputs)\n",
        "  \n",
        "  def train(self, inputs, targets):\n",
        "    # 计算网络的输出值\n",
        "    outputs = self.forward(inputs)\n",
        "    # 计算损失值\n",
        "    loss = self.loss_function(outputs, targets)\n",
        "\n",
        "    # 梯度归零，反向传播，更新权重\n",
        "    self.optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    self.optimizer.step()\n",
        "\n",
        "    # 每隔10个训练样本增加一次计数器的值，并将损失值添加进列表的末尾\n",
        "    self.counter += 1\n",
        "    if(self.counter % 10 == 0):\n",
        "      self.progress.append(loss.item())\n",
        "      pass\n",
        "    if(self.counter % 10000 == 0):\n",
        "      print(\"dicriminator counter = \", self.counter)\n",
        "      pass\n",
        "  \n",
        "  def plot_progress(self):\n",
        "    df = pandas.DataFrame(self.progress, columns=['loss'])\n",
        "    df.plot(ylim=(0,1.0), figsize=(16,8), alpha=0.1, marker='.',\n",
        "        grid=True, yticks=(0,0.25,0.5))\n",
        "    pass"
      ],
      "metadata": {
        "id": "ENTsQyu96O5Y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# 测试鉴别器\n",
        "D = Discriminator()\n",
        "for label, image_data_tensor, target_tensor in mnist_dataset:\n",
        "  # 真实数据\n",
        "  D.train(image_data_tensor, torch.FloatTensor([1.0]))\n",
        "  # 生成数据\n",
        "  D.train(generate_random(784), torch.FloatTensor([0.0]))"
      ],
      "metadata": {
        "id": "9RY7mtyB6t46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D.plot_progress()\n",
        "for i in range(4):\n",
        "  image_data_tensor = mnist_dataset[random.randint(0, 60000)][1]\n",
        "  print( D.forward(image_data_tensor).item() )\n",
        "  print( D.forward(generate_random(784)).item() )"
      ],
      "metadata": {
        "id": "yI9fG5j48MEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 构造生成器\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # 定义神经网路层\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(1, 3),\n",
        "        nn.Sigmoid(),\n",
        "        nn.Linear(3, 4),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "    # 创建优化器\n",
        "    self.optimizer = torch.optim.SGD(self.parameters(), lr=0.01)  # 使用的是生成器的parameters\n",
        "\n",
        "    # 计数器和进程记录\n",
        "    self.counter = 0\n",
        "    self.progress = []\n",
        "\n",
        "    pass\n",
        "  \n",
        "  def forward(self, inputs):\n",
        "    return self.model(inputs)\n",
        "  \n",
        "  def train(self, D, inputs, targets):\n",
        "    # 计算生成器网络输出\n",
        "    g_output = self.forward(inputs)\n",
        "\n",
        "    # 输入鉴别器\n",
        "    d_output = D.forward(g_output)\n",
        "\n",
        "    # 计算损失值\n",
        "    loss = D.loss_function(d_output, targets)\n",
        "    # 每训练10次增加计数器\n",
        "    self.counter += 1\n",
        "    if (self.counter % 10 == 0):\n",
        "      self.progress.append(loss.item())\n",
        "      pass\n",
        "    if (self.counter % 10000 == 0):\n",
        "      print(\"generator counter = \", self.counter)\n",
        "      pass\n",
        "    \n",
        "    # 梯度归零，反向传播，更新权重\n",
        "    self.optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    self.optimizer.step()    # 只更新生成器的parameter\n",
        "\n",
        "    pass\n",
        "  \n",
        "  def plot_progress(self):\n",
        "    df = pandas.DataFrame(self.progress, columns=['loss'])\n",
        "    df.plot(ylim=(0,1.0), figsize=(16,8), alpha=0.1, marker='.',\n",
        "        grid=True, yticks=(0,0.25,0.5))\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "0AVUKHVl6Xfw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}